{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading-in data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we import the required packages and modules. The last line imports the utility scoring function from the file that was published in Challenge's GitHub page. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow import TensorSpec as ts\n",
    "import pandas as pd\n",
    "from scipy.special import logit\n",
    "from matplotlib import pyplot as plt \n",
    "from tqdm import tqdm, trange\n",
    "from time import time\n",
    "from evaluate_sepsis_score import compute_prediction_utility"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up some constants that govern how many CV folds we assume and which CV fold is used for testing, as well as number of batches for mini-batch model fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "startTime = time()\n",
    "dataDir = \"../data\"\n",
    "dtype = np.double\n",
    "reloadDataFlag = False\n",
    "cvFoldN, cvFold = 5, 0\n",
    "batchN = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we import the data from the raw data files, do some truncation for the very outlying outcomes and save the preprocessed data to a single file that is much faster to load."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if reloadDataFlag:\n",
    "  subDirList = [\"original/training_A\", \"original/training_B\"]\n",
    "  dataFrames, P = [], 0\n",
    "  for subDir in subDirList:\n",
    "    files = [f for f in os.listdir(os.path.join(dataDir,subDir)) if os.path.isfile(os.path.join(dataDir,subDir, f))]\n",
    "    for f in tqdm(files):\n",
    "      df = pd.read_csv(os.path.join(dataDir,subDir,f),sep=\"|\")\n",
    "      df[\"Id\"] = P\n",
    "      dataFrames.append(df)\n",
    "      P += 1\n",
    "  dataFrame = pd.concat(dataFrames)\n",
    "  \n",
    "  for i in range(34):\n",
    "    q = np.nanquantile(dataFrame.iloc[:,i],[0,0.001,0.01,0.05,0.25,0.5,0.75,0.95,0.99,0.999,1])\n",
    "    dataFrame.iloc[:,i] = np.clip(dataFrame.iloc[:,i], q[1], q[-2])\n",
    "    plt.hist(dataFrame.iloc[:,i])\n",
    "    plt.title(str(i) + \" \" + dataFrame.columns[i])\n",
    "    plt.show()\n",
    "    print(q)\n",
    "  dataFrame.to_pickle(os.path.join(dataDir,\"all_raw_data.pkl\"))\n",
    "else:\n",
    "  dataFrame = pd.read_pickle(os.path.join(dataDir,\"all_raw_data.pkl\"))\n",
    "  P = np.unique(dataFrame[\"Id\"]).shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We handle some discrepancies in the raw data files and fill in some missing covariates values (not outcomes)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataFrame[\"Unit\"] = dataFrame[\"Unit1\"] + 2*dataFrame[\"Unit2\"] - 1 \n",
    "dataFrame.loc[np.isnan(dataFrame[\"Unit\"]),\"Unit\"] = 2\n",
    "dataFrame[\"HospAdmTime\"][np.isnan(dataFrame[\"HospAdmTime\"])] = np.nanmean(dataFrame[\"HospAdmTime\"])\n",
    "dataFrameList = [df for _, df in dataFrame.groupby(\"Id\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We reprocess the SepsisLabel column into two columns: \"Deseased\" - whether this patient will get sepsis at some point and \"Time\" time past since the patient got sepsis (is negative if patient will get sepsis in future)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for p in tqdm(range(P)):\n",
    "  df = dataFrameList[p]\n",
    "  ind = np.where(df[\"SepsisLabel\"]==1)[0]\n",
    "  if ind.size > 0:\n",
    "    indMin = ind[0]\n",
    "    df = df.assign(Time=np.maximum(df[\"ICULOS\"] - df.loc[df.index[indMin],\"ICULOS\"],-90), Deseased=1)\n",
    "  else:\n",
    "    df = df.assign(Time=np.nan, Deseased=0)\n",
    "  dataFrameList[p] = df\n",
    "dataFrame = pd.concat(dataFrameList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get numpy matrices of covariates and outcomes and perform some normalization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "YColumns = dataFrame.columns[:34]\n",
    "XColumns = [\"Time\", \"Deseased\", \"Age\", \"Gender\", \"Unit\", 'HospAdmTime', 'ICULOS', \"Id\"]\n",
    "timeColumnIndex = 6\n",
    "YAll = dataFrame[YColumns].values\n",
    "XAll = dataFrame[XColumns].values\n",
    "YScale = np.array([np.nanmean(YAll,0),np.nanstd(YAll,0)])\n",
    "XScale = np.array([np.nanmean(XAll,0),np.nanstd(XAll,0)])\n",
    "XScale[:,-1] = [0,1]\n",
    "XScale[0,0] = 0\n",
    "YAll = (YAll - YScale[0]) / YScale[1]\n",
    "XAll = (XAll - XScale[0]) / XScale[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split data to training and validation partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idVecTest = np.where((np.arange(P) % cvFoldN) == cvFold)[0]\n",
    "idVecTrain = np.setdiff1d(np.arange(P), idVecTest)\n",
    "indTrain = np.isin(XAll[:,-1], idVecTrain)\n",
    "indTest = np.isin(XAll[:,-1], idVecTest)\n",
    "XTrain, YTrain = XAll[indTrain], YAll[indTrain]\n",
    "XTest, YTest = XAll[indTest], YAll[indTest]\n",
    "\n",
    "XTrain = XTrain[:,:-1]\n",
    "XTrain[np.isnan(XTrain)] = 0\n",
    "YoTrain = (~np.isnan(YTrain)).astype(dtype)\n",
    "YTrain[np.isnan(YTrain)] = 0\n",
    "N,J = YTrain.shape\n",
    "C = XTrain.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model set up and fitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the model by specifying its (log) likelihood function. It is really important to understand how the fromula from the project description file matches its implementation here! Pay attention to how missing Y values are handled. Check Wiki page on Normal distribution for the likelihood if it seems unfamiliar.\n",
    "\n",
    "This block is the primary part (and almost the only one) that you will have to change to get to models 2 and 3. Model 4 will require a wider range of adjustments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment next line if you prefer TF eager execution mode\n",
    "@tf.function(input_signature=(ts([C,J],dtype),ts([J],dtype),ts([None,C],dtype),ts([None,J],dtype),ts([None,J],dtype)))\n",
    "def logLikelihood(B,sigma2, X,Y,Yo):\n",
    "  Mu = tf.matmul(X, B)\n",
    "  R = (Y - Mu) * Yo\n",
    "  logDetD_vec = tf.reduce_sum(Yo * tf.math.log(sigma2), 1)\n",
    "  qF_vec = tf.reduce_sum(tf.square(R) / sigma2, 1)\n",
    "  constTerm_vec = -0.5*tf.reduce_sum(Yo, 1)*np.log(2*np.pi)\n",
    "  logLike_vec = -0.5*(logDetD_vec + qF_vec) + constTerm_vec\n",
    "  logLike = tf.reduce_sum(logLike_vec)\n",
    "  return logLike, logLike_vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define the set of model parameters that will be learned and an optimizer object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = tf.Variable(tf.zeros([C,J], dtype=dtype))\n",
    "sigma2_uncon = tf.Variable(tf.zeros([J], dtype=dtype))\n",
    "par_list = [B, sigma2_uncon]\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up the optimization step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# comment next line if you prefer TF eager execution mode\n",
    "@tf.function(input_signature=(ts([None,C],dtype),ts([None,J],dtype),ts([None,J],dtype)))\n",
    "def optimizer_step(X,Y,Yo):\n",
    "  with tf.GradientTape() as tape:\n",
    "    tape.watch(par_list)\n",
    "    sigma2 = tf.math.softplus(sigma2_uncon)\n",
    "    loss = -logLikelihood(B,sigma2, X,Y,Yo)[0] * (N/tf.shape(X)[0])\n",
    "  grad_list = tape.gradient(loss, par_list)\n",
    "  optimizer.apply_gradients(zip(grad_list,par_list))\n",
    "  return loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We run the optimization cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with trange(100) as tran:\n",
    "  for epoch in tran:\n",
    "    ind = np.random.permutation(np.arange(YTrain.shape[0]))\n",
    "    for batch in range(batchN):\n",
    "      inBatchVec = ind%batchN==batch\n",
    "      X,Y,Yo = XTrain[inBatchVec],YTrain[inBatchVec],YoTrain[inBatchVec]\n",
    "      val = optimizer_step(X,Y,Yo)\n",
    "      tran.set_postfix(batch=\"%.3d\"%batch, loss=\"%015.3f\"%val.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bayes classifier based on generative model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the fitted generative model to calculate the likelihoods of the following hypotheses: A - the current patient will never ever get sepsis and B - the current patient will get sepsis at time $t_0$. Since we do not know the time $t_0$, we consider multiple opportunities. Namely, it seems reasonable that given that the current patient has been observed for $t$ hours now, we will consider thet the onset of sepsis $t_0$ could happend in any hour between $t-t_{before}$ and $t+t_{after}$.\n",
    "\n",
    "For the sake of numerical performance efficiency the code below considers the $t_0$ being in range between hour $t_{before}$ and $T + t_{after}$, where $T$ is the total number of hours that the given patiaent will stay in the ICU (number of rows in patient's dataset). Obviously, this number is not availalby in advance and therefore can result in information leak from the future. In order to cope with this issue, the further sections adjust the predictions to be in line with how they are described in previous paragraph. When you work on your own implementations, please keep in mind this potential pitfall and avoid it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testN = idVecTest.shape[0]\n",
    "sigma2 = tf.math.softplus(sigma2_uncon)\n",
    "t0SpanBefore = 12\n",
    "t0SpanAfter = 48\n",
    "t0Span = t0SpanBefore + t0SpanAfter\n",
    "logLikelihood = logLikelihood\n",
    "resArrayList = []\n",
    "with tqdm(range(testN)) as progressBar:\n",
    "  for indTest in progressBar:\n",
    "    idTest = idVecTest[indTest]\n",
    "    indIdTest = np.where(XTest[:,-1] == idTest)[0]\n",
    "    XTestId,YTestId = XTest[indIdTest,:-1].copy(), YTest[indIdTest].copy()\n",
    "    indNan = np.isnan(YTestId)\n",
    "    YoTestId = (~indNan).astype(dtype)\n",
    "    YTestId[indNan] = 0    \n",
    "    tOrig = XTestId[:,timeColumnIndex] * XScale[1,timeColumnIndex] + XScale[0,timeColumnIndex]\n",
    "    N = XTestId.shape[0]\n",
    "    resArray = np.full([N,N+t0Span], np.nan)\n",
    "    Y,Yo = tf.constant(YTestId), tf.constant(YoTestId)\n",
    "    for t0Ind in range(N+t0Span):\n",
    "      X = XTestId.copy()\n",
    "      if t0Ind==0:\n",
    "        X[:,1] = 0\n",
    "        X[:,0] = 0\n",
    "      else:\n",
    "        X[:,1] = 1\n",
    "        t0 = tOrig[0] - t0SpanBefore + t0Ind\n",
    "        X[:,0] = ((tOrig-t0)-XScale[0,0])/XScale[1,0]\n",
    "      X = tf.constant(X)\n",
    "      logLike = logLikelihood(B,sigma2, X,Y,Yo)[1]\n",
    "      resArray[:,t0Ind] = np.cumsum(logLike,0)\n",
    "    resArrayList.append(resArray)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the scoring rules of the Challenge, we compute the utility of trivial (inaction) predictions and optimal predictions. Those are used to get a score that shall be within the range $[0,1]$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_early   = -12\n",
    "dt_optimal = -6\n",
    "dt_late    = 3\n",
    "best_utilities     = np.zeros(testN)\n",
    "inaction_utilities = np.zeros(testN)\n",
    "with tqdm(range(testN)) as progressBar:\n",
    "  for indTest in progressBar:\n",
    "    idTest = idVecTest[indTest]\n",
    "    indIdTest = np.where(XTest[:,-1] == idTest)[0]\n",
    "    XTestId,YTestId = XTest[indIdTest,:-1].copy(), YTest[indIdTest].copy()\n",
    "    sepLabelVec = ~np.isnan(XTestId[:,0]) * (XTestId[:,0]>=0.0)\n",
    "    N = XTestId.shape[0]\n",
    "    best_predictions     = np.zeros(N)\n",
    "    inaction_predictions = np.zeros(N)\n",
    "    action_predictions = np.ones(N)\n",
    "    if np.any(sepLabelVec):\n",
    "      t_sepsis = np.argmax(sepLabelVec) - dt_optimal\n",
    "      best_predictions[max(0, t_sepsis + dt_early) : min(t_sepsis + dt_late + 1, N)] = 1\n",
    "    best_utilities[indTest],_ = compute_prediction_utility(sepLabelVec, best_predictions)\n",
    "    inaction_utilities[indTest],_ = compute_prediction_utility(sepLabelVec, inaction_predictions)\n",
    "unnormalized_best_utility     = np.sum(best_utilities)\n",
    "unnormalized_inaction_utility = np.sum(inaction_utilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We transform the obtained hypotheses' likelihoods into binary predictions and pass them to obtain the utilities. \n",
    "\n",
    "This section contains the largest space for testing and improvization since there is no clear optimal rule of how your model-based believes regarding whether and when the patient will get sepsis shall be transformed into final predictions. Current code implements a rule-based common sense version with some finetuning of couple parameters. But try to be creative and explore other opportunitiers (I guarantee that there are those that perform better)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "priorProb = 0.1\n",
    "dtAdvance = 6\n",
    "bfThreshhold = -0.4\n",
    "observed_utilities = np.zeros([testN])\n",
    "with tqdm(range(testN)) as progressBar:\n",
    "  for indTest in progressBar:\n",
    "    idTest = idVecTest[indTest]\n",
    "    resArray = resArrayList[indTest]\n",
    "    indIdTest =  np.where(XTest[:,-1] == idTest)[0]\n",
    "    XTestId,YTestId = XTest[indIdTest,:-1].copy(), YTest[indIdTest].copy()\n",
    "    sepLabelVec = ~np.isnan(XTestId[:,0]) * (XTestId[:,0]>=0.0)\n",
    "    N = XTestId.shape[0]\n",
    "    isPositive = np.any(sepLabelVec)\n",
    "    A = np.tri(N, N+t0Span-1, t0Span-1) - np.tri(N, N+t0Span-1, -1)\n",
    "    A[A==0] = np.nan\n",
    "    A *= resArray[:,1:]-resArray[:,0,None]\n",
    "    B = A.copy()\n",
    "    B[:,:t0SpanBefore-1] = np.nan\n",
    "    neg = np.ones([N,1])\n",
    "    pos = ~np.isnan(B)\n",
    "    pos = pos / np.sum(pos,1)[:,None]\n",
    "    C = np.concatenate([np.zeros([N,1]),B],1)\n",
    "    C[np.isnan(C)] = -np.inf\n",
    "    logPrior = np.log(np.concatenate([(1-priorProb)*neg,priorProb*pos],1))\n",
    "    unnormPostProb = np.exp(C + logPrior)\n",
    "    normPostProb = unnormPostProb / np.sum(unnormPostProb,1)[:,None]\n",
    "    postProbVec = np.sum(normPostProb[:,1:]*np.tri(N,N+t0Span-1,dtAdvance+t0SpanBefore-1),1)\n",
    "    postBF = logit(postProbVec)\n",
    "    observed_predictions = postBF > bfThreshhold \n",
    "    observed_utilities[indTest],_ = compute_prediction_utility(sepLabelVec, observed_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we print the predictive score for the current CV fold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unnormalized_observed_utility = np.sum(observed_utilities)\n",
    "normalized_observed_utility = (unnormalized_observed_utility - unnormalized_inaction_utility) / (unnormalized_best_utility - unnormalized_inaction_utility)\n",
    "print(\"\\nPredictive utility score %.3f, elapsed time %ds\"%(normalized_observed_utility, time() - startTime))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This example with linear model ends up in somewhat $0.03$ utility score if we average over the 5 CV folds. This is very far behind the methods from the top of the leaderboard, but still better than the best trivial predictions. However, this is why this model is marked as number 1, so the other onces shall generally perform better. Also, remember that you are not requested to beat them, but rahter conducting a course project that is aimed to give you practical skills on multivariate generative modelling that would be applicable in a wide range of biomedical applications."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enjoy the exciting dataset and good luck!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
